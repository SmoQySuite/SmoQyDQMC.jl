@doc raw"""
    compute_function_of_correlations(
        # ARGUMENTS
        comm::MPI.Comm;
        # KEYWORD ARGUMENTS
        f::Function,
        datafolder::String,
        correlations::AbstractVector{<:NamedTuple},
        num_bins::Int = 0,
        pIDs::Vector{Int} = Int[],
    )

    compute_function_of_correlations(;
        # KEYWORD ARGUMENTS
        f::Function,
        datafolder::String,
        correlations::AbstractVector{<:NamedTuple},
        num_bins::Int = 0,
        pIDs::Union{Int,Vector{Int}} = Int[]
    )

Calculate the mean and error associated with computing a function of measured correlation functions.

The correlation measurements that are passed as arguments to the function to evaluate are specified by the vector
of named tuples `correlations`. The keys of the named tuple used to specify the correlation measurements are given below:

- `name::String`: Name of correlation function.
- `type::String`: Specifies whether to use "EQUAL-TIME", "TIME-DISPLACED" or "INTEGRATED" correlation measurement.
- `id_pair::NTuple{2,Int}`: If a standard correlation measurement, then specifies the ID pair for the correlation measurement.
- `R::NTuple{D,Int}` xor `K::NTuple{D,Int}`: Specifies either displacement vector or momentum point in `D` dimensions.
- `τ::Float64` xor `l::Int`: Imaginary-time or imaginary-time slice used if the `type` is "TIME-DISPLACED".

# Keyword Arguments

- `f::Function`: The function to evaluate.
- `datafolder::String`: Output directory generated by SmoQyDQMC simulation.
- `correlations::AbstractVector{NamedTuple}`: Vector of named tuples specifying the correlation measurement function arguments.
- `num_bins::Int = 0`: Number of bins used to compute statistics. If zero then use all number of bins.
- `pIDs = Int[]`: Process ID's used when measuring function of correlation measurements. If is `Int[]`, then all process ID's are used.
"""
function compute_function_of_correlations(
    # ARGUMENTS
    comm::MPI.Comm;
    # KEYWORD ARGUMENTS
    f::Function,
    datafolder::String,
    correlations::AbstractVector{<:NamedTuple},
    num_bins::Int = 0,
    pIDs::Vector{Int} = Int[],
)

    # number of MPI processes
    N_mpi = MPI.Comm_size(comm)

    # determine relevant pIDs
    pIDs = isempty(pIDs) ? collect(0:N_mpi-1) : pIDs
    pID = pIDs[MPI.Comm_rank(comm) + 1]

    # initialize version of function that take the sign as the first argument
    # and ensure re-weighting is performed when evaluating the function
    F(z...) = f(map(x->x/z[1], z[2:end])...)

    # calculate the composite correlation
    C, ΔC = jackknife(F, binned_sign, binned_correlations..., bias_corrected=false)

    return C, ΔC
end

function compute_function_of_correlations(;
    # KEYWORD ARGUMENTS
    f::Function,
    datafolder::String,
    correlations::AbstractVector{NamedTuple},
    num_bins::Int = 0,
    pIDs::Union{Int,Vector{Int}} = Int[]
)

    # determine relevant process IDs
    pIDs = isa(pIDs, Int) ? [pIDs,] : pIDs
    if isempty(pIDs)
        pIDs = collect( 0 : length(readdir(joinpath(datafolder,"bins")))-1 )
    end

    # number of process IDs
    N_pID = length(pIDs)

    # open all the input HDF5 bin files
    H5BinFiles = [h5open(joinpath(datafolder, "bins", "bins_pID-$(pID).h5"), "r") for pID in pIDs]

    # get the total number of bins per pID
    n_bins = read_attribute(H5BinFiles[1], "N_BINS")

    # determine the number of bins to use to calculate statistics
    num_bins = iszero(num_bins) ? n_bins : num_bins
    @assert iszero(mod(num_bins, n_bins)) "num_bins = $(num_bins) is not a factor of the number of data bins per pID, $(n_bins)."

    # read in binned sign data
    binned_sign = vcat((
        rebin(read(h5["GLOBAL/sgn"]), num_bins) for h5 in H5BinFiles
    )...)

    # read in the binned sign data
    binned_correlations = tuple((
        (
            rebin(
                _read_correlation_bins(),
                num_bins
            )
            for h5 in H5BinFiles
        )
        for correlation in correlations
    )...)

    # initialize version of function that take the sign as the first argument
    # and ensure re-weighting is performed when evaluating the function
    F(z...) = f(map(x->x/z[1], z[2:end])...)

    # calculate the composite correlation
    C, ΔC = jackknife(F, binned_sign, binned_correlations..., bias_corrected=false)

    # close all the H5 bin files
    close.(H5BinFiles)

    return C, ΔC
end


# calculate function of correlation based on single HDF5 file containing
# the binned data for one walker
function _compute_function_of_correlations(
    f::Function,
    datafolder::String,
    pID::Int,
    correlations::Vector{<:NamedTuple},
    num_bins::Int
)

    # get HDF5 filename containing binned data
    filename = joinpath(datafolder, "bins", "bins_pID-$(pID).h5")

    # open HDF5 file containing binned data
    h5 = h5open(filename, "r")

    # get the total number of bins per pID
    n_bins = read_attribute(h5, "N_BINS")

    # determine the number of bins to use to calculate statistics
    num_bins = iszero(num_bins) ? read_attribute(h5, "N_BINS") : num_bins

    # read in binned sign
    binned_sign = bin_means(read(h5["GLOBAL/sgn"]), num_bins)

    # real type
    R = real(eltype(binned_sign))

    # initialize vector to contain binned values
    binned_correlations = Vector{Vector{Complex{R}}}(undef, length(correlations))

    # iterate over correlations to read in
    for n in eachindex(binned_correlations)

        # get the binned correlation data
        binned_correlations[n] = _read_correlation_bins(h5, correlations[n], num_bins)
    end

    # initialize version of function that take the sign as the first argument
    # and ensure re-weighting is performed when evaluating the function
    F(z...) = f(map(x->x/z[1], z[2:end])...)

    # calculate the composite correlation
    C, ΔC = jackknife(F, binned_sign, binned_correlations..., bias_corrected=false)

    # close HDF5 file containing binned data
    close(h5)

    return C, ΔC
end


# given a named tuple describing a given correlation function,
# read in the binned data for that correlation function measurement
# from the HDF5 file
function _read_correlation_bins(
    h5::HDF5.File,
    correlation::NamedTuple
)

    # extract name of correlation
    name = lowercase(correlation.name)

    # whether a standard or composite correlation measurement
    category = haskey(CORRELATION_FUNCTIONS, name) ? "STANDARD" : "COMPOSITE"
    @assert(
        (category != "STANDARD") || haskey(correlation, :id_pair),
        "For standard correlation measurements an :id_pair needs to be defined."
    )

    # extract displacement vector of momentum point and record which one it is
    @assert(
        haskey(correlation, :R) || haskey(correlation, :K),
        "A displacement vector :R or momentum point :K must be specified."
    )
    entry, space = haskey(correlation, :R) ? (tuple(map(r -> r+1, correlation.R)...), "POSITION") : (tuple(map(k -> k+1, correlation.K)...), "MOMENTUM")

    # the type of correlation measurement
    type = uppercase(correlation.type)
    @assert(
        (type != "TIME-DISPLACED") || (haskey(correlation, :l) ⊻ haskey(correlation, :τ)),
        "For time-displaced correlation measurement imaginary-time :τ xor slice :l must be specified"
    )

    # get relevant correlation dataset
    CorrelationGroup = h5["CORRELATIONS"][category][type][name]
    DataSet = CorrelationGroup[space]

    # if time-displaced correlation measurement
    if type == "TIME-DISPLACED"

        # read in discretization in imaginary-time
        Δτ = read_attribute(h5, "DELTA_TAU")

        # make sure valid imaginary-time is passed
        @assert(
            (haskey(correlation, :l)) || iszero(mod(correlation.τ, Δτ)),
            "The passed imaginary-time :τ cannot be mapped to an imaginary-time slice as (τ%Δτ)≠0."
        )

        # get the imaginary-time slice
        l = haskey(correlation, :l) ? correlation.l+1 : round(Int, correlation.τ/Δτ)+1

        # if a standard correlation measurement
        if category == "STANDARD"

            # get the id pair
            id_pair = correlation.id_pair

            # get the corresponding index
            all_id_pairs = map(p -> tuple(p...), read_attribute(CorrelationGroup, "ID_PAIRS"))

            # get the dataset index associated with ID pair
            i = findfirst(p -> p == id_pair, all_id_pairs)

            # extract the binned values
            binned_vals = DataSet[:,entry...,l,i]

        # if a composite correlation measurement
        else

            # extract the binned values
            binned_vals = DataSet[:,entry...,l]
        end
    else

        # if a standard correlation measurement
        if category == "STANDARD"

            # get the id pair
            id_pair = correlation.id_pair

            # get the corresponding index
            all_id_pairs = map(p -> tuple(p...), read_attribute(CorrelationGroup, "ID_PAIRS"))

            # get the dataset index associated with ID pair
            i = findfirst(p -> p == id_pair, all_id_pairs)

            # extract the binned values
            binned_vals = DataSet[:,entry...,i]

        # if a composite correlation measurement
        else

            # extract the binned values
            binned_vals = DataSet[:,entry...]
        end
    end

    return binned_vals
end