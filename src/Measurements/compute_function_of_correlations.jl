@doc raw"""
    compute_function_of_correlations(
        # ARGUMENTS
        comm::MPI.Comm;
        # KEYWORD ARGUMENTS
        f::Function,
        datafolder::String,
        correlations::AbstractVector{<:NamedTuple},
        num_bins::Int = 0,
        pIDs::Vector{Int} = Int[],
    )

    compute_function_of_correlations(;
        # KEYWORD ARGUMENTS
        f::Function,
        datafolder::String,
        correlations::AbstractVector{<:NamedTuple},
        num_bins::Int = 0,
        pIDs::Union{Int,Vector{Int}} = Int[]
    )

Calculate the mean and error associated with computing a function of measured correlation functions.

The correlation measurements that are passed as arguments to the function to evaluate are specified by the vector
of named tuples `correlations`. The keys of the named tuple used to specify the correlation measurements are given below:

- `name::String`: Name of correlation function.
- `type::String`: Specifies whether to use "EQUAL-TIME", "TIME-DISPLACED" or "INTEGRATED" correlation measurement.
- `id_pair::NTuple{2,Int}`: If a standard correlation measurement, then specifies the ID pair for the correlation measurement.
- `R::NTuple{D,Int}` xor `K::NTuple{D,Int}`: Specifies either displacement vector or momentum point in `D` dimensions.
- `τ::Float64` xor `l::Int`: Imaginary-time or imaginary-time slice used if the `type` is "TIME-DISPLACED".

# Keyword Arguments

- `f::Function`: The function to evaluate.
- `datafolder::String`: Output directory generated by SmoQyDQMC simulation.
- `correlations::AbstractVector{NamedTuple}`: Vector of named tuples specifying the correlation measurement function arguments.
- `num_bins::Int = 0`: Number of bins used to compute statistics. If zero then use all number of bins.
- `pIDs = Int[]`: Process ID's used when measuring function of correlation measurements. If is `Int[]`, then all process ID's are used.
"""
function compute_function_of_correlations(
    # ARGUMENTS
    comm::MPI.Comm;
    # KEYWORD ARGUMENTS
    f::Function,
    datafolder::String,
    correlations::AbstractVector{<:NamedTuple},
    num_bins::Int = 0,
    pIDs::Vector{Int} = Int[],
)

    # number of MPI processes
    N_mpi = MPI.Comm_size(comm)

    # determine relevant pIDs
    pIDs = isempty(pIDs) ? collect(0:N_mpi-1) : pIDs
    pID = pIDs[MPI.Comm_rank(comm) + 1]

    # if root process
    isroot = iszero(pID)

    # get HDF5 filename containing binned data
    filename = joinpath(datafolder, "bins", "bins_pID-$(pID).h5")

    # open HDF5 file containing binned data
    H5BinFile = h5open(filename, "r")

    # get the binned sign data
    binned_sign = read(H5BinFile["GLOBAL/sgn"])

    # get number of bins per process
    n_bins = length(binned_sign)
    num_bins = iszero(num_bins) ? n_bins : num_bins
    @assert iszero(mod(num_bins, n_bins)) "num_bins = $(num_bins) is not a factor of the number of data bins per pID, $(n_bins)."

    # rebin the sign data
    binned_sign = rebin(binned_sign, num_bins)

    # gather sign data onto root process
    binned_sign = MPI.gather(binned_sign, comm)
    binned_sign = isroot ? vcat(binned_sign...) : nothing

    # get the data type
    R = isroot ? real(eltype(binned_sign)) : nothing

    # initialize vector to contain binned values
    binned_correlations = isroot ? Vector{Vector{Complex{R}}}(undef, 0) : nothing

    # iterate over correlations
    for correlation in correlations
        
        # read in the binned correlation
        binned_correlation = rebin(_read_correlation_bins(H5BinFile, correlation), num_bins)

        # gather the binned correlation data
        binned_correlation = MPI.gather(binned_correlation, comm)

        # record the correlation data
        if isroot
            push!(binned_correlations, vcat(binned_correlation...))
        end
    end

    # if is root process
    if isroot

        # initialize version of function that take the sign as the first argument
        # and ensure re-weighting is performed when evaluating the function
        F(z...) = f(map(x->x/z[1], z[2:end])...)

        # calculate the composite correlation
        C, ΔC = jackknife(F, binned_sign, binned_correlations..., bias_corrected=false)
    else

        C, ΔC = nothing, nothing
    end

    # broadcast the number to all processes
    C = MPI.bcast(C, comm)
    ΔC = MPI.bcast(ΔC, comm)

    # close the H5 file
    close(H5BinFile)

    return C, ΔC
end

function compute_function_of_correlations(;
    # KEYWORD ARGUMENTS
    f::Function,
    datafolder::String,
    correlations::AbstractVector{NamedTuple},
    num_bins::Int = 0,
    pIDs::Union{Int,Vector{Int}} = Int[]
)

    # determine relevant process IDs
    pIDs = isa(pIDs, Int) ? [pIDs,] : pIDs
    if isempty(pIDs)
        pIDs = collect( 0 : length(readdir(joinpath(datafolder,"bins")))-1 )
    end

    # number of process IDs
    N_pID = length(pIDs)

    # open all the input HDF5 bin files
    H5BinFiles = [h5open(joinpath(datafolder, "bins", "bins_pID-$(pID).h5"), "r") for pID in pIDs]

    # get the total number of bins per pID
    n_bins = read_attribute(H5BinFiles[1], "N_BINS")

    # determine the number of bins to use to calculate statistics
    num_bins = iszero(num_bins) ? n_bins : num_bins
    @assert iszero(mod(num_bins, n_bins)) "num_bins = $(num_bins) is not a factor of the number of data bins per pID, $(n_bins)."

    # read in binned sign data
    binned_sign = vcat((
        vcat((rebin(read(h5["GLOBAL/sgn"]), num_bins) for h5 in H5BinFiles)...)
    )...)

    # read in the binned sign data
    binned_correlations = [
        (vcat((rebin(_read_correlation_bins(h5, correlation),num_bins) for h5 in H5BinFiles)...)
         for correlation in correlations)...
    ]

    # initialize version of function that take the sign as the first argument
    # and ensure re-weighting is performed when evaluating the function
    F(z...) = f(map(x->x/z[1], z[2:end])...)

    # calculate the composite correlation
    C, ΔC = jackknife(F, binned_sign, binned_correlations..., bias_corrected=false)

    # close all the H5 bin files
    close.(H5BinFiles)

    return C, ΔC
end


# given a named tuple describing a given correlation function,
# read in the binned data for that correlation function measurement
# from the HDF5 file
function _read_correlation_bins(
    h5::HDF5.File,
    correlation::NamedTuple
)

    # extract name of correlation
    name = lowercase(correlation.name)

    # whether a standard or composite correlation measurement
    category = haskey(CORRELATION_FUNCTIONS, name) ? "STANDARD" : "COMPOSITE"
    @assert(
        (category != "STANDARD") || haskey(correlation, :id_pair),
        "For standard correlation measurements an :id_pair needs to be defined."
    )

    # extract displacement vector of momentum point and record which one it is
    @assert(
        haskey(correlation, :R) || haskey(correlation, :K),
        "A displacement vector :R or momentum point :K must be specified."
    )
    entry, space = haskey(correlation, :R) ? (tuple(map(r -> r+1, correlation.R)...), "POSITION") : (tuple(map(k -> k+1, correlation.K)...), "MOMENTUM")

    # the type of correlation measurement
    type = uppercase(correlation.type)
    @assert(
        (type != "TIME-DISPLACED") || (haskey(correlation, :l) ⊻ haskey(correlation, :τ)),
        "For time-displaced correlation measurement imaginary-time :τ xor slice :l must be specified"
    )

    # get relevant correlation dataset
    CorrelationGroup = h5["CORRELATIONS"][category][type][name]
    DataSet = CorrelationGroup[space]

    # if time-displaced correlation measurement
    if type == "TIME-DISPLACED"

        # read in discretization in imaginary-time
        Δτ = read_attribute(h5, "DELTA_TAU")

        # make sure valid imaginary-time is passed
        @assert(
            (haskey(correlation, :l)) || iszero(mod(correlation.τ, Δτ)),
            "The passed imaginary-time :τ cannot be mapped to an imaginary-time slice as (τ%Δτ)≠0."
        )

        # get the imaginary-time slice
        l = haskey(correlation, :l) ? correlation.l+1 : round(Int, correlation.τ/Δτ)+1

        # if a standard correlation measurement
        if category == "STANDARD"

            # get the id pair
            id_pair = correlation.id_pair

            # get the corresponding index
            all_id_pairs = map(p -> tuple(p...), read_attribute(CorrelationGroup, "ID_PAIRS"))

            # get the dataset index associated with ID pair
            i = findfirst(p -> p == id_pair, all_id_pairs)

            # extract the binned values
            binned_vals = DataSet[:,entry...,l,i]

        # if a composite correlation measurement
        else

            # extract the binned values
            binned_vals = DataSet[:,entry...,l]
        end

    # if equal-time or integrated correlation measurement
    else

        # if a standard correlation measurement
        if category == "STANDARD"

            # get the id pair
            id_pair = correlation.id_pair

            # get the corresponding index
            all_id_pairs = map(p -> tuple(p...), read_attribute(CorrelationGroup, "ID_PAIRS"))

            # get the dataset index associated with ID pair
            i = findfirst(p -> p == id_pair, all_id_pairs)

            # extract the binned values
            binned_vals = DataSet[:,entry...,i]

        # if a composite correlation measurement
        else

            # extract the binned values
            binned_vals = DataSet[:,entry...]
        end
    end

    return binned_vals
end